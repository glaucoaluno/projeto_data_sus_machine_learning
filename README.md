# AnÃ¡lise de Mortalidade com Machine Learning

## Autores

**Alunos**:
- Elisangela Oliveira (CP301492X)
- Glauco Neto (CP3025845)
- Wellington Gomes (CP3025853)

**Disciplina**: IntroduÃ§Ã£o ao Aprendizado de MÃ¡quina  
**InstituiÃ§Ã£o**: IFSP  
**Data**: 2025

## ğŸ“‹ Resumo do Projeto

Este projeto implementa tÃ©cnicas de Machine Learning para prever a causa de morte com base em caracterÃ­sticas demogrÃ¡ficas e contextuais. Utiliza dados reais de mortalidade do Brasil fornecidos pelo DATASUS (Sistema de InformaÃ§Ãµes sobre Mortalidade - SIM).

---

## ğŸ¯ Objetivo

Desenvolver e comparar trÃªs modelos de classificaÃ§Ã£o para prever a causa bÃ¡sica do Ã³bito (CAUSABAS) a partir de variÃ¡veis demogrÃ¡ficas e caracterÃ­sticas da morte, contribuindo para a anÃ¡lise epidemiolÃ³gica de padrÃµes de mortalidade.

---

## ğŸ“Š Fonte de Dados

**Dataset**: Dados de Mortalidade 2024 - DATASUS  
**Origem**: https://opendatasus.saude.gov.br/  
**Formato**: CSV com delimitador `;`
**Tamanho**: ~494 MB (~1 milhÃ£o de registros)
**Colunas**: 88 variÃ¡veis

### VariÃ¡veis Utilizadas

#### **Features (VariÃ¡veis Independentes)**
- **SEXO**: Sexo do falecido (1 = Masculino, 2 = Feminino)
- **IDADE_CALCULADA**: Idade em anos (0-120)
- **RACACOR**: RaÃ§a/Cor (1 = Branca, 2 = Preta, 3 = Amarela, 4 = Parda, 5 = IndÃ­gena)
- **ESC2010**: Escolaridade (0 = Sem escolaridade atÃ© 5 = Superior completo)
- **LOCOCOR**: Local de ocorrÃªncia (1 = Hospital, 2 = Outro, 3 = DomicÃ­lio, 4 = Via pÃºblica, etc.)
- **CIRCOBITO**: CircunstÃ¢ncia do Ã³bito (1 = Acidente, 2 = SuicÃ­dio, 3 = HomicÃ­dio, 9 = Ignorado)

#### **Target (VariÃ¡vel Dependente)**
- **CAUSABAS**: Causa bÃ¡sica do Ã³bito (CÃ³digo CID-10)

---

## ğŸ”§ Metodologia

### **1. PrÃ©-processamento de Dados**

#### Carregamento
- Leitura do arquivo CSV com encoding `latin1`
- Tratamento de erros e validaÃ§Ã£o de dimensÃµes
- VerificaÃ§Ã£o de disponibilidade de variÃ¡veis

#### Limpeza
- RemoÃ§Ã£o de valores ausentes (dropna)
- SeleÃ§Ã£o de 6 features demogrÃ¡ficas e contextuais
- Filtro de dados incompletos

#### SimplificaÃ§Ã£o da VariÃ¡vel Alvo
- ExtraÃ§Ã£o da primeira letra do cÃ³digo CID-10
- ReduÃ§Ã£o de ~500 categorias para ~20 principais
- Filtro de categorias com menos de 1000 casos
- Resultado: 10-15 classes principais

#### CodificaÃ§Ã£o de VariÃ¡veis
- **LabelEncoder** para variÃ¡veis categÃ³ricas
- ConversÃ£o de 5 features categÃ³ricas em valores numÃ©ricos
- Armazenamento de encoders para uso futuro

---

### **2. PreparaÃ§Ã£o dos Dados**

#### DivisÃ£o Treino/Teste
- **ProporÃ§Ã£o**: 70% treino, 30% teste
- **EstratificaÃ§Ã£o**: MantÃ©m proporÃ§Ã£o de classes em ambos os conjuntos
- **Random State**: 42 (reprodutibilidade)

#### NormalizaÃ§Ã£o
- **StandardScaler**: PadronizaÃ§Ã£o com mÃ©dia 0 e desvio padrÃ£o 1
- **Fit em treino**: Evita data leakage
- **Transform em teste**: Aplica mesma transformaÃ§Ã£o

#### Balanceamento de Classes
- **SMOTE** (Synthetic Minority Over-sampling Technique)
- Cria amostras sintÃ©ticas de classes minoritÃ¡rias
- Aplicado apenas no conjunto de treino
- Resolve desbalanceamento de classes

---

### **3. Modelos de Machine Learning**

#### **Modelo 1: RegressÃ£o LogÃ­stica**
- **Tipo**: ClassificaÃ§Ã£o linear
- **CaracterÃ­sticas**:
  - Simples e interpretÃ¡vel
  - RÃ¡pido para treinar
  - Serve como baseline
  - Bom para dados linearmente separÃ¡veis
- **HiperparÃ¢metros**:
  - `max_iter=1000`
  - `random_state=42`

#### **Modelo 2: Random Forest**
- **Tipo**: Ensemble de Ã¡rvores de decisÃ£o
- **CaracterÃ­sticas**:
  - Captura relaÃ§Ãµes nÃ£o-lineares
  - Robusto a outliers
  - Fornece importÃ¢ncia das features
  - Generaliza bem
- **HiperparÃ¢metros**:
  - `n_estimators=100` (100 Ã¡rvores)
  - `random_state=42`

#### **Modelo 3: XGBoost**
- **Tipo**: Gradient Boosting otimizado
- **CaracterÃ­sticas**:
  - Estado-da-arte em performance
  - Otimizado para dados desbalanceados
  - RegularizaÃ§Ã£o integrada
  - Melhor tratamento de features
- **HiperparÃ¢metros**:
  - `n_estimators=100`
  - `max_depth=6`
  - `learning_rate=0.1`
  - `subsample=0.8`
  - `colsample_bytree=0.8`

---

### **4. AvaliaÃ§Ã£o dos Modelos**

#### MÃ©tricas Utilizadas

**AcurÃ¡cia**
- ProporÃ§Ã£o de prediÃ§Ãµes corretas
- FÃ³rmula: (TP + TN) / Total
- Intervalo: 0 a 1

**PrecisÃ£o**
- De todas as prediÃ§Ãµes positivas, quantas estÃ£o corretas?
- FÃ³rmula: TP / (TP + FP)
- Importante quando falsos positivos sÃ£o custosos

**Recall (Sensibilidade)**
- De todos os casos positivos, quantos foram identificados?
- FÃ³rmula: TP / (TP + FN)
- Importante quando falsos negativos sÃ£o custosos

**F1-Score**
- MÃ©dia harmÃ´nica entre precisÃ£o e recall
- FÃ³rmula: 2 Ã— (PrecisÃ£o Ã— Recall) / (PrecisÃ£o + Recall)
- Ideal para dados desbalanceados

#### AnÃ¡lises Adicionais
- **Matriz de ConfusÃ£o**: Verdadeiros/falsos positivos/negativos
- **RelatÃ³rio de ClassificaÃ§Ã£o**: MÃ©tricas por classe
- **ImportÃ¢ncia das Features**: Ranking de relevÃ¢ncia
- **ComparaÃ§Ã£o de Modelos**: Tabela com todas as mÃ©tricas

---

### **5. AnÃ¡lise de ImportÃ¢ncia das Features**

#### Random Forest
- Extrai `feature_importances_` de cada Ã¡rvore
- Calcula mÃ©dia ponderada
- Identifica features mais relevantes

#### XGBoost
- Calcula ganho (gain) de cada feature
- Considera nÃºmero de splits
- Compara com Random Forest

**Resultado**: Ranking de features que mais contribuem para a prediÃ§Ã£o

---

## ğŸ“ˆ Resultados Esperados

### Desempenho dos Modelos
- **RegressÃ£o LogÃ­stica**: Baseline, acurÃ¡cia ~60-70%
- **Random Forest**: Melhor generalizaÃ§Ã£o, acurÃ¡cia ~75-85%
- **XGBoost**: Melhor performance, acurÃ¡cia ~80-90%

### Features Mais Importantes
1. Idade
2. Sexo
3. Local de ocorrÃªncia
4. Escolaridade
5. RaÃ§a/Cor
6. CircunstÃ¢ncia do Ã³bito

### Insights Esperados
- PadrÃµes de mortalidade por idade e sexo
- RelaÃ§Ã£o entre escolaridade e causa de morte
- DiferenÃ§as por raÃ§a/cor
- InfluÃªncia do local de ocorrÃªncia

---

## ğŸ› ï¸ Tecnologias Utilizadas

### Bibliotecas Python
- **pandas**: ManipulaÃ§Ã£o de dados
- **numpy**: ComputaÃ§Ã£o numÃ©rica
- **scikit-learn**: Modelos de ML e prÃ©-processamento
- **xgboost**: Gradient Boosting
- **imbalanced-learn**: SMOTE para balanceamento
- **matplotlib/seaborn**: VisualizaÃ§Ãµes
- **requests**: Download de dados remoto
- **zipfile**: ExtraÃ§Ã£o de arquivos

### VersÃµes Recomendadas
```
pandas >= 1.3.0
numpy >= 1.21.0
scikit-learn >= 1.0.0
xgboost >= 1.5.0
imbalanced-learn >= 0.8.0
matplotlib >= 3.4.0
seaborn >= 0.11.0
requests >= 2.26.0
```

---

## ğŸš€ Como Executar

### PrÃ©-requisitos
- Python 3.7+
- pip ou conda
- ConexÃ£o com internet (primeira execuÃ§Ã£o)

### InstalaÃ§Ã£o de DependÃªncias
```bash
pip install -r requirements.txt
```

### ExecuÃ§Ã£o
```bash
jupyter lab
```

### Primeira ExecuÃ§Ã£o
- Download do arquivo ZIP do DATASUS (~100 MB)
- ExtraÃ§Ã£o e processamento dos dados
- Treinamento dos 3 modelos
- GeraÃ§Ã£o de visualizaÃ§Ãµes
- **Tempo estimado**: 5-15 minutos

### ExecuÃ§Ãµes Subsequentes
- Usa cache local do arquivo CSV
- Muito mais rÃ¡pido (~5-15 minutos)
- Sem necessidade de internet

---

## ğŸ“Š SaÃ­das Geradas

### Console Output
- Progresso do carregamento de dados
- MÃ©tricas de cada modelo
- Matriz de confusÃ£o
- RelatÃ³rio de classificaÃ§Ã£o
- ImportÃ¢ncia das features
- ComparaÃ§Ã£o de desempenho

### VisualizaÃ§Ãµes
- GrÃ¡fico de comparaÃ§Ã£o de acurÃ¡cia
- Matriz de confusÃ£o (heatmap)
- Top 6 features - Random Forest
- Top 6 features - XGBoost
- Arquivo PNG em alta resoluÃ§Ã£o (300 DPI)

### Arquivos Salvos
- GrÃ¡ficos em formato PNG
- Arquivo CSV em cache local (primeira execuÃ§Ã£o)

---

## ğŸ” InterpretaÃ§Ã£o dos Resultados

### AcurÃ¡cia Alta (>80%)
- âœ… Modelo tem boa performance
- âœ… Pode ser usado para prediÃ§Ãµes
- âœ… Considerar ensemble de modelos

### AcurÃ¡cia Moderada (60-80%)
- Performance aceitÃ¡vel
- Considerar ajuste de hiperparÃ¢metros
- Adicionar mais features

### AcurÃ¡cia Baixa (<60%)
- âœ— Performance fraca
- âœ— Revisar prÃ©-processamento
- âœ— Considerar diferentes features

### ImportÃ¢ncia das Features
- Features com alta importÃ¢ncia: Mais relevantes para prediÃ§Ã£o
- Features com baixa importÃ¢ncia: Podem ser removidas
- ComparaÃ§Ã£o entre modelos: Validar consistÃªncia

---

## ğŸ“ Estrutura do Desenvolvimento

### Fase 1: ExploraÃ§Ã£o
- Carregamento de dados
- AnÃ¡lise descritiva
- IdentificaÃ§Ã£o de padrÃµes

### Fase 2: PrÃ©-processamento
- Limpeza de dados
- Tratamento de valores ausentes
- CodificaÃ§Ã£o de variÃ¡veis
- NormalizaÃ§Ã£o

### Fase 3: Modelagem
- DivisÃ£o treino/teste
- Balanceamento de classes
- Treinamento de 3 modelos
- AvaliaÃ§Ã£o inicial

### Fase 4: AvaliaÃ§Ã£o
- CÃ¡lculo de mÃ©tricas
- AnÃ¡lise de importÃ¢ncia
- ComparaÃ§Ã£o de modelos
- GeraÃ§Ã£o de visualizaÃ§Ãµes

### Fase 5: InterpretaÃ§Ã£o
- AnÃ¡lise de resultados
- IdentificaÃ§Ã£o de insights
- RecomendaÃ§Ãµes

---

## ConsideraÃ§Ãµes Importantes

### Qualidade dos Dados
- Dataset contÃ©m valores "Ignorado" em algumas variÃ¡veis
- Alguns registros podem ter informaÃ§Ãµes incompletas
- Dados refletem padrÃµes de 2024

### Desbalanceamento de Classes
- Algumas causas de morte sÃ£o mais frequentes
- SMOTE ajuda a resolver, mas nÃ£o elimina completamente
- F1-Score Ã© mais apropriado que acurÃ¡cia

### CorrelaÃ§Ã£o vs Causalidade
- AnÃ¡lises mostram correlaÃ§Ãµes, nÃ£o causalidade
- Features importantes nÃ£o implicam relaÃ§Ã£o causal
- InterpretaÃ§Ã£o requer conhecimento epidemiolÃ³gico

### ValidaÃ§Ã£o
- Sempre validar em dados nÃ£o vistos
- Considerar validaÃ§Ã£o cruzada
- Monitorar performance em dados novos

---

## Aprendizados

Este projeto demonstra:
- ClassificaÃ§Ã£o multiclasse com dados reais
- PrÃ©-processamento completo de dados
- Balanceamento de classes (SMOTE)
- ComparaÃ§Ã£o de mÃºltiplos modelos
- AvaliaÃ§Ã£o robusta com mÃºltiplas mÃ©tricas
- AnÃ¡lise de importÃ¢ncia de features
- VisualizaÃ§Ãµes profissionais
- Boas prÃ¡ticas de ML

---

## ReferÃªncias

### DocumentaÃ§Ã£o
- [Scikit-learn](https://scikit-learn.org/)
- [XGBoost](https://xgboost.readthedocs.io/)
- [Imbalanced-learn](https://imbalanced-learn.org/)

### Dados
- [DATASUS](https://datasus.saude.gov.br/)
- [OpenDataSUS](https://opendatasus.saude.gov.br/)
- [SIM - Sistema de InformaÃ§Ãµes sobre Mortalidade](https://www.gov.br/saude/pt-br/acesso-a-informacao/acoes-e-programas/sistema-de-informacoes-sobre-mortalidade-sim)

### Conceitos
- [CID-10](https://www.who.int/standards/classifications/classification-of-diseases)
- [Machine Learning](https://en.wikipedia.org/wiki/Machine_learning)
- [SMOTE](https://arxiv.org/abs/1106.1813)

---

## LicenÃ§a

Este projeto utiliza dados pÃºblicos do DATASUS e segue as diretrizes de uso de dados abertos do governo brasileiro.