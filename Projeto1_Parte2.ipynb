{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0db9bf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CÉLULA 1: IMPORTAÇÕES E CONFIGURAÇÕES INICIAIS\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Importação das bibliotecas necessárias para o projeto de Machine Learning\n",
    "para predição de causas de óbito no dataset DATASUS.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import os\n",
    "from IPython.display import display\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, accuracy_score, \n",
    "    precision_recall_fscore_support, roc_auc_score, roc_curve, auc\n",
    ")\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "# Modelos\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Configurações\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b31a9a",
   "metadata": {},
   "source": [
    "### OBJETIVO DO PROJETO:\n",
    "Prever a causa básica de óbito (CAUSABAS) utilizando características demográficas\n",
    "e circunstâncias do óbito do dataset DATASUS (DO24OPEN).\n",
    "\n",
    "### RELEVÂNCIA:\n",
    "Este projeto é relevante para:\n",
    "- Análise epidemiológica: Identificar padrões nas causas de morte\n",
    "- Saúde pública: Auxiliar na alocação de recursos e políticas de prevenção\n",
    "- Predição: Classificar óbitos em categorias de causa para análise automática\n",
    "\n",
    "### TÉCNICAS UTILIZADAS:\n",
    "1. Regressão Logística: Modelo linear interpretável para classificação\n",
    "2. Random Forest: Ensemble com múltiplas árvores para capturar não-linearidades\n",
    "3. SVM (Support Vector Machine): Modelo não-linear para classificação multiclasse (TÉCNICA EXTRA)\n",
    "4. XGBoost: Gradient boosting avançado para melhor performance\n",
    "\n",
    "### METODOLOGIA:\n",
    "- Pré-processamento: Limpeza, encoding, normalização\n",
    "- Balanceamento: SMOTE para lidar com desbalanceamento de classes\n",
    "- Validação: Cross-validation e divisão treino/teste\n",
    "- Otimização: Grid Search para hiperparâmetros\n",
    "- Avaliação: Múltiplas métricas (Acurácia, Precisão, Recall, F1-Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8396bea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CÉLULA 3: FUNÇÃO PARA CARREGAMENTO DE DADOS\n",
    "# =============================================================================\n",
    "def carregar_csv_do_zip_remoto(url_zip, nome_csv = None, cache_local = True):\n",
    "    \"\"\"\n",
    "    Carrega um arquivo CSV de um ZIP remoto com cache local\n",
    "    \n",
    "    Parâmetros:\n",
    "    -----------\n",
    "    url_zip : str\n",
    "        URL do arquivo ZIP\n",
    "    nome_csv : str, optional\n",
    "        Nome do arquivo CSV dentro do ZIP\n",
    "    cache_local : bool, default=True\n",
    "        Se True, salva o CSV localmente\n",
    "    \n",
    "    Retorna:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame com os dados carregados\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"CARREGANDO DADOS DE FORMA REMOTA\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Verificar se arquivo local existe\n",
    "    if cache_local and nome_csv and os.path.exists(nome_csv):\n",
    "        print(f\"\\nArquivo local encontrado: {nome_csv}\")\n",
    "        print(\"  Carregando do cache local...\")\n",
    "        try:\n",
    "            df = pd.read_csv(nome_csv, delimiter=';', low_memory=False, encoding='latin1')\n",
    "            print(f\"Dataset carregado com sucesso!\")\n",
    "            print(f\"Dimensões: {df.shape[0]} linhas x {df.shape[1]} colunas\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao carregar arquivo local: {e}\")\n",
    "            print(\"Tentando baixar novamente...\")\n",
    "    \n",
    "    print(f\"\\nBaixando arquivo ZIP remoto...\")\n",
    "    print(f\"   URL: {url_zip}\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url_zip, timeout=300)\n",
    "        response.raise_for_status()\n",
    "        print(f\"Download concluído ({len(response.content) / (1024**2):.2f} MB)\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao baixar: {e}\")\n",
    "        raise\n",
    "    \n",
    "    print(f\"\\nExtraindo arquivo ZIP...\")\n",
    "    try:\n",
    "        zip_file = zipfile.ZipFile(io.BytesIO(response.content))\n",
    "        print(f\"Arquivos no ZIP: {zip_file.namelist()}\")\n",
    "    except Exception as e:\n",
    "        print(f\" Erro ao extrair ZIP: {e}\")\n",
    "        raise\n",
    "    \n",
    "    if nome_csv is None:\n",
    "        csv_files = [f for f in zip_file.namelist() if f.endswith('.csv')]\n",
    "        if not csv_files:\n",
    "            raise ValueError(\"Nenhum arquivo CSV encontrado no ZIP\")\n",
    "        nome_csv = csv_files[0]\n",
    "        print(f\"Arquivo CSV encontrado: {nome_csv}\")\n",
    "    \n",
    "    print(f\"\\nLendo arquivo CSV...\")\n",
    "    try:\n",
    "        with zip_file.open(nome_csv) as csv_file:\n",
    "            df = pd.read_csv(csv_file, delimiter=';', low_memory=False, encoding='latin1')\n",
    "        print(f\"✓ Dataset carregado com sucesso!\")\n",
    "        print(f\"  Dimensões: {df.shape[0]} linhas × {df.shape[1]} colunas\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Erro ao ler CSV: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # Salvar localmente (cache)\n",
    "    if cache_local:\n",
    "        print(f\"\\nSalvando arquivo localmente para futuras execuções...\")\n",
    "        try:\n",
    "            df.to_csv(nome_csv, index=False, sep=';', encoding='latin1')\n",
    "            print(f\" Arquivo salvo: {nome_csv}\")\n",
    "        except Exception as e:\n",
    "            print(f\" Aviso: Não foi possível salvar localmente: {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cffe7e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CARREGANDO DADOS DE FORMA REMOTA\n",
      "================================================================================\n",
      "\n",
      "Arquivo local encontrado: DO24OPEN.csv\n",
      "  Carregando do cache local...\n",
      "Dataset carregado com sucesso!\n",
      "Dimensões: 1426346 linhas x 86 colunas\n",
      "\n",
      "Dados carregados!\n",
      "Shape: (1426346, 86)\n",
      "\n",
      "Primeiras linhas:\n",
      "   contador  ORIGEM  TIPOBITO   DTOBITO  HORAOBITO  NATURAL  CODMUNNATU  \\\n",
      "0         1       1         2  19042024     2301.0    824.0    240490.0   \n",
      "1         2       1         2  18012024     1030.0    824.0    240940.0   \n",
      "2         3       1         2  22012024      700.0    824.0    241250.0   \n",
      "3         4       1         2  24032024     1220.0    824.0    241050.0   \n",
      "4         5       1         2  12012024      800.0    824.0    240320.0   \n",
      "\n",
      "       DTNASC  IDADE  SEXO  RACACOR  ESTCIV  ESC  ESC2010  SERIESCFAL  \\\n",
      "0  24121964.0    459     1      1.0     1.0  1.0      0.0         NaN   \n",
      "1  29041958.0    465     2      1.0     2.0  5.0      5.0         NaN   \n",
      "2  23031939.0    484     2      4.0     2.0  1.0      0.0         NaN   \n",
      "3  10061944.0    479     2      1.0     2.0  9.0      9.0         NaN   \n",
      "4   8031950.0    473     2      2.0     5.0  1.0      0.0         NaN   \n",
      "\n",
      "       OCUP  CODMUNRES  LOCOCOR   CODESTAB  CODMUNOCOR  IDADEMAE  ESCMAE  \\\n",
      "0  622020.0     240490        1  2407582.0      240490       NaN     NaN   \n",
      "1       NaN     241050        3        NaN      241050       NaN     NaN   \n",
      "2  622005.0     241050        3        NaN      241050       NaN     NaN   \n",
      "3       NaN     241050        3        NaN      241050       NaN     NaN   \n",
      "4       NaN     240320        3        NaN      240320       NaN     NaN   \n",
      "\n",
      "   ESCMAE2010  SERIESCMAE  OCUPMAE  QTDFILVIVO  QTDFILMORT  GRAVIDEZ  \\\n",
      "0         NaN         NaN      NaN         NaN         NaN       NaN   \n",
      "1         NaN         NaN      NaN         NaN         NaN       NaN   \n",
      "2         NaN         NaN      NaN         NaN         NaN       NaN   \n",
      "3         NaN         NaN      NaN         NaN         NaN       NaN   \n",
      "4         NaN         NaN      NaN         NaN         NaN       NaN   \n",
      "\n",
      "   SEMAGESTAC  GESTACAO  PARTO  OBITOPARTO  PESO  TPMORTEOCO  OBITOGRAV  \\\n",
      "0         NaN       NaN    NaN         NaN   NaN         NaN        NaN   \n",
      "1         NaN       NaN    NaN         NaN   NaN         9.0        9.0   \n",
      "2         NaN       NaN    NaN         NaN   NaN         NaN        NaN   \n",
      "3         NaN       NaN    NaN         NaN   NaN         NaN        NaN   \n",
      "4         NaN       NaN    NaN         NaN   NaN         NaN        NaN   \n",
      "\n",
      "   OBITOPUERP  ASSISTMED  EXAME  CIRURGIA  NECROPSIA LINHAA LINHAB LINHAC  \\\n",
      "0         NaN        1.0    NaN       NaN        NaN  *J81X  *I500  *I279   \n",
      "1         9.0        9.0    NaN       NaN        9.0  *I219  *A09X    NaN   \n",
      "2         NaN        9.0    NaN       NaN        9.0  *I219  *I10X  *E112   \n",
      "3         NaN        9.0    NaN       NaN        9.0  *J969  *J189  *G309   \n",
      "4         NaN        1.0    NaN       NaN        2.0  *I219  *I509  *I10X   \n",
      "\n",
      "  LINHAD LINHAII CAUSABAS  CB_PRE  COMUNSVOIM  DTATESTADO  CIRCOBITO  \\\n",
      "0  *I10X     NaN     I279     NaN         NaN  19042024.0        NaN   \n",
      "1    NaN     NaN      A09     NaN         NaN  18012024.0        NaN   \n",
      "2    NaN     NaN     E112     NaN         NaN  22012024.0        NaN   \n",
      "3    NaN     NaN     G309     NaN         NaN  25032024.0        NaN   \n",
      "4    NaN     NaN     I219     NaN         NaN  12012024.0        NaN   \n",
      "\n",
      "   ACIDTRAB  FONTE  NUMEROLOTE  DTINVESTIG  DTCADASTRO  ATESTANTE STCODIFICA  \\\n",
      "0       NaN    NaN  20240003.0         NaN   3052024.0        2.0          S   \n",
      "1       NaN    NaN  20240003.0         NaN   6022024.0        1.0          S   \n",
      "2       NaN    NaN  20240003.0         NaN   6022024.0        1.0          S   \n",
      "3       NaN    NaN  20240007.0         NaN  12042024.0        1.0          S   \n",
      "4       NaN    NaN  20240001.0         NaN   5022024.0        1.0          S   \n",
      "\n",
      "  CODIFICADO VERSAOSIST  VERSAOSCB  FONTEINV  DTRECEBIM           ATESTADO  \\\n",
      "0          S     3.2.30        3.4       NaN  8052024.0  J81/I500/I279/I10   \n",
      "1          S     3.2.30        3.4       NaN  6022024.0           I219/A09   \n",
      "2          S     3.2.30        3.4       NaN  6022024.0      I219/I10/E112   \n",
      "3          S     3.2.30        3.4       NaN  8052024.0     J969/J189/G309   \n",
      "4          S     3.2.30        3.4       NaN  6022024.0      I219/I509/I10   \n",
      "\n",
      "   DTRECORIGA  OPOR_DO CAUSAMAT  ESCMAEAGR1  ESCFALAGR1  STDOEPIDEM  STDONOVA  \\\n",
      "0     8052024       19      NaN         NaN         0.0         0.0         1   \n",
      "1     6022024       19      NaN         NaN         8.0         0.0         1   \n",
      "2     6022024       15      NaN         NaN         0.0         0.0         1   \n",
      "3     8052024       45      NaN         NaN         9.0         0.0         1   \n",
      "4     6022024       25      NaN         NaN         0.0         0.0         1   \n",
      "\n",
      "   DIFDATA  NUDIASOBCO  DTCADINV  TPOBITOCOR  DTCONINV FONTES  TPRESGINFO  \\\n",
      "0       19         NaN       NaN         NaN       NaN    NaN         NaN   \n",
      "1       19         NaN       NaN         NaN       NaN    NaN         NaN   \n",
      "2       15         NaN       NaN         NaN       NaN    NaN         NaN   \n",
      "3       45         NaN       NaN         NaN       NaN    NaN         NaN   \n",
      "4       25         NaN       NaN         NaN       NaN    NaN         NaN   \n",
      "\n",
      "  TPNIVELINV  DTCADINF  MORTEPARTO  DTCONCASO  ALTCAUSA CAUSABAS_O TPPOS  \\\n",
      "0        NaN       NaN         NaN        NaN       NaN       I279     N   \n",
      "1        NaN       NaN         NaN        NaN       NaN        A09     N   \n",
      "2        NaN       NaN         NaN        NaN       NaN       E112     N   \n",
      "3        NaN       NaN         NaN        NaN       NaN       G309     N   \n",
      "4        NaN       NaN         NaN        NaN       NaN       I219     N   \n",
      "\n",
      "   TP_ALTERA CB_ALT  \n",
      "0        NaN    NaN  \n",
      "1        NaN    NaN  \n",
      "2        NaN    NaN  \n",
      "3        NaN    NaN  \n",
      "4        NaN    NaN  \n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CÉLULA 4: CARREGAMENTO DO DATASET\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Carregamento do dataset DATASUS com dados de óbitos.\n",
    "URL oficial do DATASUS para dados de 2024.\n",
    "\"\"\"\n",
    "\n",
    "url_zip = \"https://s3.sa-east-1.amazonaws.com/ckan.saude.gov.br/SIM/csv/DO24OPEN_csv.zip\"\n",
    "\n",
    "# Carregar dados\n",
    "df = carregar_csv_do_zip_remoto(\n",
    "    url_zip = url_zip,\n",
    "    nome_csv = 'DO24OPEN.csv',\n",
    "    cache_local = True\n",
    ")\n",
    "\n",
    "# Exibir informações\n",
    "print(\"\\nDados carregados!\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"\\nPrimeiras linhas:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1dd0555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1] EXPLORAÇÃO INICIAL DOS DADOS...\n",
      "Dataset carregado com sucesso!\n",
      "  Dimensões: 1426346 linhas × 86 colunas\n",
      "\n",
      "Colunas disponíveis:\n",
      "['contador', 'ORIGEM', 'TIPOBITO', 'DTOBITO', 'HORAOBITO', 'NATURAL', 'CODMUNNATU', 'DTNASC', 'IDADE', 'SEXO', 'RACACOR', 'ESTCIV', 'ESC', 'ESC2010', 'SERIESCFAL', 'OCUP', 'CODMUNRES', 'LOCOCOR', 'CODESTAB', 'CODMUNOCOR', 'IDADEMAE', 'ESCMAE', 'ESCMAE2010', 'SERIESCMAE', 'OCUPMAE', 'QTDFILVIVO', 'QTDFILMORT', 'GRAVIDEZ', 'SEMAGESTAC', 'GESTACAO', 'PARTO', 'OBITOPARTO', 'PESO', 'TPMORTEOCO', 'OBITOGRAV', 'OBITOPUERP', 'ASSISTMED', 'EXAME', 'CIRURGIA', 'NECROPSIA', 'LINHAA', 'LINHAB', 'LINHAC', 'LINHAD', 'LINHAII', 'CAUSABAS', 'CB_PRE', 'COMUNSVOIM', 'DTATESTADO', 'CIRCOBITO', 'ACIDTRAB', 'FONTE', 'NUMEROLOTE', 'DTINVESTIG', 'DTCADASTRO', 'ATESTANTE', 'STCODIFICA', 'CODIFICADO', 'VERSAOSIST', 'VERSAOSCB', 'FONTEINV', 'DTRECEBIM', 'ATESTADO', 'DTRECORIGA', 'OPOR_DO', 'CAUSAMAT', 'ESCMAEAGR1', 'ESCFALAGR1', 'STDOEPIDEM', 'STDONOVA', 'DIFDATA', 'NUDIASOBCO', 'DTCADINV', 'TPOBITOCOR', 'DTCONINV', 'FONTES', 'TPRESGINFO', 'TPNIVELINV', 'DTCADINF', 'MORTEPARTO', 'DTCONCASO', 'ALTCAUSA', 'CAUSABAS_O', 'TPPOS', 'TP_ALTERA', 'CB_ALT']\n",
      "\n",
      "Tipos de dados:\n",
      "contador        int64\n",
      "ORIGEM          int64\n",
      "TIPOBITO        int64\n",
      "DTOBITO         int64\n",
      "HORAOBITO     float64\n",
      "               ...   \n",
      "ALTCAUSA      float64\n",
      "CAUSABAS_O     object\n",
      "TPPOS          object\n",
      "TP_ALTERA     float64\n",
      "CB_ALT         object\n",
      "Length: 86, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CÉLULA 5: EXPLORAÇÃO INICIAL DOS DADOS\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Análise exploratória inicial do dataset para entender estrutura e tipos de dados.\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n[1] EXPLORAÇÃO INICIAL DOS DADOS...\")\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv('DO24OPEN.csv', delimiter=';', low_memory=False, encoding='latin1')\n",
    "    print(f\"Dataset carregado com sucesso!\")\n",
    "    print(f\"  Dimensões: {df.shape[0]} linhas × {df.shape[1]} colunas\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao carregar: {e}\")\n",
    "    exit()\n",
    "\n",
    "print(\"\\nColunas disponíveis:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "print(\"\\nTipos de dados:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "929027cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variáveis selecionadas: ['SEXO', 'RACACOR', 'ESC2010', 'LOCOCOR', 'CIRCOBITO', 'CAUSABAS']\n",
      "\n",
      "Dataset para ML: (1426346, 6)\n",
      "Valores ausentes:\n",
      "SEXO               0\n",
      "RACACOR        19445\n",
      "ESC2010        91225\n",
      "LOCOCOR            0\n",
      "CIRCOBITO    1283156\n",
      "CAUSABAS           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CÉLULA 6: SELEÇÃO DE VARIÁVEIS RELEVANTES\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Seleção das variáveis mais relevantes para o modelo de Machine Learning.\n",
    "Variáveis escolhidas com base em relevância epidemiológica e disponibilidade.\n",
    "\"\"\"\n",
    "\n",
    "# Seleção de variáveis relevantes para predição\n",
    "# Variáveis demográficas e características da morte\n",
    "variaveis_selecionadas = [\n",
    "    'IDADE_CALCULADA',  # Idade\n",
    "    'SEXO',              # Sexo (1=Masculino, 2=Feminino)\n",
    "    'RACACOR',           # Raça/Cor\n",
    "    'ESC2010',           # Escolaridade\n",
    "    'LOCOCOR',           # Local de ocorrência\n",
    "    'CIRCOBITO',         # Circunstância do óbito\n",
    "    'CAUSABAS'           # Causa básica (alvo)\n",
    "]\n",
    "\n",
    "# Verificar quais colunas existem\n",
    "colunas_existentes = [col for col in variaveis_selecionadas if col in df.columns]\n",
    "print(f\"Variáveis selecionadas: {colunas_existentes}\")\n",
    "\n",
    "# Criar dataset com variáveis selecionadas\n",
    "df_ml = df[colunas_existentes].copy()\n",
    "\n",
    "print(f\"\\nDataset para ML: {df_ml.shape}\")\n",
    "print(f\"Valores ausentes:\\n{df_ml.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98e2c2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2] ANÁLISE E REMOÇÃO DE OUTLIERS...\n",
      "\n",
      "Outliers removidos: 54422 linhas\n",
      "Dimensões do dataset após remoção de outliers: 0 linhas x 86 colunas\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CÉLULA 7: ANÁLISE E REMOÇÃO DE OUTLIERS\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Detecção e remoção de outliers usando método IQR (Interquartile Range).\n",
    "Outliers podem distorcer o treinamento dos modelos.\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n[2] ANÁLISE E REMOÇÃO DE OUTLIERS...\")\n",
    "\n",
    "# Selecionar colunas numéricas para análise de outliers\n",
    "numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# Calcular IQR para cada coluna\n",
    "iqr_values = {}\n",
    "for col in numeric_columns:\n",
    "    q1 = df[col].quantile(0.25)\n",
    "    q3 = df[col].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    iqr_values[col] = iqr\n",
    "\n",
    "# Identificar outliers\n",
    "outliers = {}\n",
    "for col in numeric_columns:\n",
    "    lower_bound = df[col].quantile(0.25) - 1.5 * iqr_values[col]\n",
    "    upper_bound = df[col].quantile(0.75) + 1.5 * iqr_values[col]\n",
    "    outliers[col] = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "\n",
    "# Remover outliers\n",
    "for col in numeric_columns:\n",
    "    df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "\n",
    "print(f\"\\nOutliers removidos: {outliers['IDADE'].shape[0]} linhas\")\n",
    "print(f\"Dimensões do dataset após remoção de outliers: {df.shape[0]} linhas x {df.shape[1]} colunas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63cac128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[4] TRATAMENTO DA VARIÁVEL ALVO (CAUSABAS)...\n",
      "\n",
      "Distribuição de causas (top 10):\n",
      "CAUSABAS\n",
      "I219    84189\n",
      "J189    58934\n",
      "R99     48773\n",
      "I64     32454\n",
      "I10     31055\n",
      "C349    28372\n",
      "N390    27756\n",
      "G309    26281\n",
      "A419    23612\n",
      "E149    22485\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribuição após agrupamento:\n",
      "CAUSABAS_AGRUPADA\n",
      "Outras    1042435\n",
      "I219        84189\n",
      "J189        58934\n",
      "R99         48773\n",
      "I64         32454\n",
      "I10         31055\n",
      "C349        28372\n",
      "N390        27756\n",
      "G309        26281\n",
      "A419        23612\n",
      "E149        22485\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CÉLULA 8: TRATAMENTO DA VARIÁVEL ALVO (CAUSABAS)\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Agrupamento das causas de óbito menos frequentes em categoria \"Outras\"\n",
    "para reduzir dimensionalidade e melhorar performance dos modelos.\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n[4] TRATAMENTO DA VARIÁVEL ALVO (CAUSABAS)...\")\n",
    "\n",
    "# Verificar distribuição da causa básica\n",
    "print(f\"\\nDistribuição de causas (top 10):\")\n",
    "print(df_ml['CAUSABAS'].value_counts().head(10))\n",
    "\n",
    "# Agrupar causas menos frequentes em \"Outras\"\n",
    "# Manter apenas as 10 principais causas\n",
    "top_causas = df_ml['CAUSABAS'].value_counts().head(10).index\n",
    "df_ml['CAUSABAS_AGRUPADA'] = df_ml['CAUSABAS'].apply(\n",
    "    lambda x: x if x in top_causas else 'Outras'\n",
    ")\n",
    "\n",
    "print(f\"\\nDistribuição após agrupamento:\")\n",
    "print(df_ml['CAUSABAS_AGRUPADA'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "daaddb1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset após remover NaN: (133658, 7)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CÉLULA 9: LIMPEZA DE DADOS\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Remoção de valores ausentes e preparação para encoding.\n",
    "\"\"\"\n",
    "# Remover linhas com valores ausentes\n",
    "df_ml = df_ml.dropna()\n",
    "print(f\"Dataset após remover NaN: {df_ml.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f320166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[5] CODIFICAÇÃO DE VARIÁVEIS CATEGÓRICAS...\n",
      "\n",
      "Variáveis de entrada (X): (133658, 5)\n",
      "Variável alvo (y): (133658,)\n",
      "Classes: ['C349' 'I10' 'I219' 'I64' 'J189' 'Outras' 'R99']\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CÉLULA 10: CODIFICAÇÃO DE VARIÁVEIS CATEGÓRICAS\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Transformação de variáveis categóricas para numéricas usando LabelEncoder.\n",
    "Essencial para que os modelos de Machine Learning possam processar os dados.\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n[5] CODIFICAÇÃO DE VARIÁVEIS CATEGÓRICAS...\")\n",
    "\n",
    "# Separar variáveis numéricas e categóricas\n",
    "X = df_ml.drop(['CAUSABAS', 'CAUSABAS_AGRUPADA'], axis=1)\n",
    "y = df_ml['CAUSABAS_AGRUPADA']\n",
    "\n",
    "# Dicionário para armazenar encoders\n",
    "label_encoders = {}\n",
    "\n",
    "# Codificar variáveis categóricas\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        X[col] = le.fit_transform(X[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "        print(f\"  ✓ {col} codificado\")\n",
    "\n",
    "        # Codificar variável alvo\n",
    "le_target = LabelEncoder()\n",
    "y_encoded = le_target.fit_transform(y)\n",
    "\n",
    "print(f\"\\nVariáveis de entrada (X): {X.shape}\")\n",
    "print(f\"Variável alvo (y): {y_encoded.shape}\")\n",
    "print(f\"Classes: {le_target.classes_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52affd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CÉLULA 11: DIVISÃO DOS DADOS EM TREINO E TESTE\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Divisão estratificada dos dados em conjuntos de treino (80%) e teste (20%).\n",
    "Estratificação garante distribuição similar das classes em ambos os conjuntos.\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n[6] DIVISÃO DOS DADOS...\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, test_size = 0.2, random_state = 42, stratify = y_encoded\n",
    ")\n",
    "\n",
    "print(f\"Conjunto de treino: {X_train.shape}\")\n",
    "print(f\"Conjunto de teste: {X_test.shape}\")\n",
    "print(f\"\\nDistribuição no treino:\\n{pd.Series(y_train).value_counts()}\")\n",
    "print(f\"\\nDistribuição no teste:\\n{pd.Series(y_test).value_counts()}\")\n",
    "\n",
    "# Aplicação de SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "# para balancear as classes no conjunto de treino, evitando bias do modelo.\n",
    "smote = SMOTE(random_state = 42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"Treino após SMOTE: {X_train_balanced.shape}\")\n",
    "print(f\"Distribuição após SMOTE:\\n{pd.Series(y_train_balanced).value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eca0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CÉLULA 13: NORMALIZAÇÃO DOS DADOS\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Aplicação de StandardScaler para normalizar as features.\n",
    "Essencial para modelos sensíveis à escala como Regressão Logística e SVM.\n",
    "\"\"\"\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_balanced)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc37ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CÉLULA 14: SELEÇÃO DE ATRIBUTOS (FEATURE SELECTION)\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Seleção das features mais relevantes usando SelectKBest com f_classif.\n",
    "Reduz dimensionalidade e melhora performance dos modelos.\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n[14] SELEÇÃO DE ATRIBUTOS...\")\n",
    "\n",
    "# Usar SelectKBest para selecionar as melhores features\n",
    "selector = SelectKBest(f_classif, k='all')\n",
    "X_train_selected = selector.fit_transform(X_train_balanced, y_train_balanced)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "print(f\"\\nFeatures selecionadas: {selected_features.tolist()}\")\n",
    "print(f\"Dimensão do dataset selecionado: {X_selected.shape[1]}\")\n",
    "\n",
    "# Treinar os modelos com as features selecionadas\n",
    "models_selected = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'SVM': SVC(),\n",
    "    'XGBoost': XGBClassifier()\n",
    "}\n",
    "\n",
    "for model_name, model in models_selected.items():\n",
    "    model.fit(X_selected, y_train)\n",
    "    y_pred = model.predict(X_selected)\n",
    "    print(f\"\\nModelo: {model_name}\")\n",
    "    print(classification_report(y_train, y_pred))\n",
    "    print(confusion_matrix(y_train, y_pred))\n",
    "    print(\"Acurácia: \", accuracy_score(y_train, y_pred))\n",
    "    print(\"Precisão: \", precision_score(y_train, y_pred, average='macro'))\n",
    "    print(\"Recall: \", recall_score(y_train, y_pred, average='macro'))\n",
    "    print(\"F1-Score: \", f1_score(y_train, y_pred, average='macro'))\n",
    "\n",
    "# Salvar os modelos treinados\n",
    "for model_name, model in models_selected.items():\n",
    "    joblib.dump(model, f\"model_{model_name.lower()}.joblib\")\n",
    "\n",
    "print(\"\\nModelos treinados e salvo com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c212d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CÉLULA 15: TÉCNICA 1 - REGRESSÃO LOGÍSTICA\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Treinamento de Regressão Logística com Grid Search e validação cruzada.\n",
    "Modelo baseline interpretável para classificação multiclasse.\n",
    "\"\"\"\n",
    "\n",
    "param_grid_lr = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear', 'saga']\n",
    "}\n",
    "\n",
    "grid_lr = GridSearchCV(\n",
    "    estimator = LogisticRegression(max_iter=1000),\n",
    "    param_grid = param_grid_lr,\n",
    "    cv = 5,\n",
    "    scoring = 'accuracy',\n",
    "    n_jobs = -1,\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "grid_lr.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nMelhores parâmetros para Regressão Logística:\")\n",
    "print(grid_lr.best_params_)\n",
    "\n",
    "y_pred_lr = grid_lr.predict(X_test)\n",
    "\n",
    "print(\"\\nRelatório de classificação para Regressão Logística:\")\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "\n",
    "print(\"\\nMatriz de confusão para Regressão Logística:\")\n",
    "print(confusion_matrix(y_test, y_pred_lr))\n",
    "\n",
    "print(\"\\nAcurácia para Regressão Logística:\")\n",
    "print(accuracy_score(y_test, y_pred_lr))\n",
    "\n",
    "print(\"\\nPrecisão para Regressão Logística:\")\n",
    "print(precision_score(y_test, y_pred_lr, average = 'macro'))\n",
    "\n",
    "print(\"\\nRecall para Regressão Logística:\")\n",
    "print(recall_score(y_test, y_pred_lr, average = 'macro'))\n",
    "\n",
    "print(\"\\nF1 - Score para Regressão Logística:\")\n",
    "print(f1_score(y_test, y_pred_lr, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a0ec26",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Visualizar matriz de confusão\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=le_target.classes_, yticklabels=le_target.classes_)\n",
    "plt.title('Matriz de Confusão - Regressão Logística')\n",
    "plt.ylabel('Verdadeiro')\n",
    "plt.xlabel('Predito')\n",
    "plt.tight_layout()\n",
    "plt.savefig('matriz_confusao_lr.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb2c164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CÉLULA 16: TÉCNICA 2 - RANDOM FOREST\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Treinamento de Random Forest com Grid Search e validação cruzada.\n",
    "Ensemble robusto que captura relações não-lineares.\n",
    "\"\"\"\n",
    "\n",
    "# Grid Search para otimizar hiperparâmetros\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [10, 15, 20],\n",
    "    'min_samples_split': [5, 10]\n",
    "}\n",
    "\n",
    "rf_base = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "grid_search_rf = GridSearchCV(rf_base, param_grid_rf, cv=5, scoring='f1_weighted', n_jobs=-1)\n",
    "grid_search_rf.fit(X_train_selected, y_train_balanced)\n",
    "\n",
    "print(f\"Melhores parâmetros (RF): {grid_search_rf.best_params_}\")\n",
    "print(f\"Melhor score CV (RF): {grid_search_rf.best_score_:.4f}\")\n",
    "\n",
    "rf_model = grid_search_rf.best_estimator_\n",
    "\n",
    "# Validação cruzada\n",
    "cv_scores_rf = cross_val_score(rf_model, X_train_selected, y_train_balanced, cv=5, scoring='f1_weighted')\n",
    "print(f\"Cross-validation scores (RF): {cv_scores_rf}\")\n",
    "print(f\"Média CV (RF): {cv_scores_rf.mean():.4f} (+/- {cv_scores_rf.std():.4f})\")\n",
    "\n",
    "# Predições\n",
    "y_pred_rf = rf_model.predict(X_test_selected)\n",
    "y_pred_proba_rf = rf_model.predict_proba(X_test_selected)\n",
    "\n",
    "# Avaliação\n",
    "print(\"\\nRESULTADOS - RANDOM FOREST:\")\n",
    "print(f\"Acurácia: {accuracy_score(y_test, y_pred_rf):.4f}\")\n",
    "print(f\"Precisão (média): {precision_score(y_test, y_pred_rf, average='weighted', zero_division=0):.4f}\")\n",
    "print(f\"Recall (média): {recall_score(y_test, y_pred_rf, average='weighted', zero_division=0):.4f}\")\n",
    "print(f\"F1-Score (média): {f1_score(y_test, y_pred_rf, average='weighted', zero_division=0):.4f}\")\n",
    "\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_test, y_pred_rf, target_names=le_target.classes_, zero_division=0))\n",
    "\n",
    "print(\"\\nMatriz de Confusão:\")\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "print(cm_rf)\n",
    "\n",
    "# Visualizar matriz de confusão\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Greens',\n",
    "            xticklabels=le_target.classes_, yticklabels=le_target.classes_)\n",
    "plt.title('Matriz de Confusão - Random Forest')\n",
    "plt.ylabel('Verdadeiro')\n",
    "plt.xlabel('Predito')\n",
    "plt.tight_layout()\n",
    "plt.savefig('matriz_confusao_rf.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Importância das features\n",
    "feature_importance_rf = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance_rf['feature'], feature_importance_rf['importance'])\n",
    "plt.xlabel('Importância')\n",
    "plt.title('Importância das Features - Random Forest')\n",
    "plt.tight_layout()\n",
    "plt.savefig('importancia_features_rf.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c63384b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CÉLULA 17: TÉCNICA 3 - SUPPORT VECTOR MACHINE (SVM) - TÉCNICA EXTRA\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Treinamento de Support Vector Machine com Grid Search e validação cruzada.\n",
    "Técnica não vista em sala para pontuação extra.\n",
    "\"\"\"\n",
    "\n",
    "# Grid Search para SVM\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "svm_base = SVC(random_state=42, probability=True)\n",
    "grid_search_svm = GridSearchCV(svm_base, param_grid_svm, cv=5, scoring='f1_weighted', n_jobs=-1)\n",
    "grid_search_svm.fit(X_train_scaled_selected, y_train_balanced)\n",
    "\n",
    "print(f\"Melhores parâmetros (SVM): {grid_search_svm.best_params_}\")\n",
    "print(f\"Melhor score CV (SVM): {grid_search_svm.best_score_:.4f}\")\n",
    "svm_model = grid_search_svm.best_estimator_\n",
    "\n",
    "# Validação cruzada\n",
    "cv_scores_svm = cross_val_score(svm_model, X_train_scaled_selected, y_train_balanced, cv=5, scoring='f1_weighted')\n",
    "print(f\"Cross-validation scores (SVM): {cv_scores_svm}\")\n",
    "print(f\"Média CV (SVM): {cv_scores_svm.mean():.4f} (+/- {cv_scores_svm.std():.4f})\")\n",
    "\n",
    "# Predições\n",
    "y_pred_svm = svm_model.predict(X_test_scaled_selected)\n",
    "y_pred_proba_svm = svm_model.predict_proba(X_test_scaled_selected)\n",
    "\n",
    "# Avaliação\n",
    "print(\"\\nRESULTADOS - SUPPORT VECTOR MACHINE:\")\n",
    "print(f\"Acurácia: {accuracy_score(y_test, y_pred_svm):.4f}\")\n",
    "print(f\"Precisão (média): {precision_score(y_test, y_pred_svm, average='weighted', zero_division=0):.4f}\")\n",
    "print(f\"Recall (média): {recall_score(y_test, y_pred_svm, average='weighted', zero_division=0):.4f}\")\n",
    "print(f\"F1-Score (média): {f1_score(y_test, y_pred_svm, average='weighted', zero_division=0):.4f}\")\n",
    "\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_test, y_pred_svm, target_names=le_target.classes_, zero_division=0))\n",
    "\n",
    "print(\"\\nMatriz de Confusão:\")\n",
    "cm_svm = confusion_matrix(y_test, y_pred_svm)\n",
    "print(cm_svm)\n",
    "\n",
    "# Visualizar matriz de confusão\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_svm, annot=True, fmt='d', cmap='Purples',\n",
    "            xticklabels=le_target.classes_, yticklabels=le_target.classes_)\n",
    "plt.title('Matriz de Confusão - SVM')\n",
    "plt.ylabel('Verdadeiro')\n",
    "plt.xlabel('Predito')\n",
    "plt.tight_layout()\n",
    "plt.savefig('matriz_confusao_svm.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac397d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CÉLULA 18: TÉCNICA 4 - XGBOOST\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Treinamento de XGBoost com Grid Search e validação cruzada.\n",
    "Gradient boosting avançado para melhor performance.\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TÉCNICA 4: XGBOOST\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nTreinando modelo de XGBoost com Grid Search...\")\n",
    "\n",
    "# Grid Search para XGBoost\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [5, 6, 7],\n",
    "    'learning_rate': [0.05, 0.1]\n",
    "}\n",
    "\n",
    "xgb_base = XGBClassifier(random_state=42, n_jobs=-1, verbosity=0)\n",
    "grid_search_xgb = GridSearchCV(xgb_base, param_grid_xgb, cv=5, scoring='f1_weighted', n_jobs=-1)\n",
    "grid_search_xgb.fit(X_train_selected, y_train_balanced)\n",
    "\n",
    "print(\"\\nMelhores parâmetros encontrados:\")\n",
    "print(grid_search_xgb.best_params_)\n",
    "\n",
    "# Treinar o modelo final com os melhores parâmetros\n",
    "xgb_final = grid_search_xgb.best_estimator_\n",
    "xgb_final.fit(X_train_selected, y_train_balanced)\n",
    "\n",
    "# Validação cruzada\n",
    "cv_scores_xgb = cross_val_score(xgb_model, X_train_selected, y_train_balanced, cv=5, scoring='f1_weighted')\n",
    "print(f\"Cross-validation scores (XGB): {cv_scores_xgb}\")\n",
    "print(f\"Média CV (XGB): {cv_scores_xgb.mean():.4f} (+/- {cv_scores_xgb.std():.4f})\")\n",
    "\n",
    "# Avaliar o modelo final\n",
    "y_pred_xgb = xgb_final.predict(X_test_selected)\n",
    "y_pred_proba_xgb = xgb_model.predict_proba(X_test_selected)\n",
    "\n",
    "print(\"\\nResultados do modelo final:\")\n",
    "print(classification_report(y_test_balanced, y_pred_xgb))\n",
    "\n",
    "# Salvar o modelo final\n",
    "joblib.dump(xgb_final, 'xgboost_final.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ab0b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliação\n",
    "print(\"\\nRESULTADOS - XGBOOST:\")\n",
    "print(f\"Acurácia: {accuracy_score(y_test, y_pred_xgb):.4f}\")\n",
    "print(f\"Precisão (média): {precision_score(y_test, y_pred_xgb, average='weighted', zero_division=0):.4f}\")\n",
    "print(f\"Recall (média): {recall_score(y_test, y_pred_xgb, average='weighted', zero_division=0):.4f}\")\n",
    "print(f\"F1-Score (média): {f1_score(y_test, y_pred_xgb, average='weighted', zero_division=0):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70100d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_test, y_pred_xgb, target_names=le_target.classes_, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0ac7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMatriz de Confusão:\")\n",
    "cm_xgb = confusion_matrix(y_test, y_pred_xgb)\n",
    "print(cm_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36c69f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar matriz de confusão\n",
    "plt.figure(figsize = (10, 8))\n",
    "sns.heatmap(cm_xgb, annot = True, fmt = 'd', cmap = 'Oranges',\n",
    "            xticklabels = le_target.classes_, yticklabels = le_target.classes_)\n",
    "plt.title('Matriz de Confusão - XGBoost')\n",
    "plt.ylabel('Verdadeiro')\n",
    "plt.xlabel('Predito')\n",
    "plt.tight_layout()\n",
    "plt.savefig('matriz_confusao_xgb.png', dpi = 300, bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92c0e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importância das features\n",
    "feature_importance_xgb = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': xgb_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6487005d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nImportância das Features (XGBoost):\")\n",
    "print(feature_importance_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266da377",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance_xgb['feature'], feature_importance_xgb['importance'])\n",
    "plt.xlabel('Importância')\n",
    "plt.title('Importância das Features - XGBoost')\n",
    "plt.tight_layout()\n",
    "plt.savefig('importancia_features_xgb.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9def2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CÉLULA 19: COMPARAÇÃO DOS MODELOS\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Comparação visual e numérica entre todos os modelos treinados.\n",
    "Identificação do melhor modelo com base nas métricas de avaliação.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7920ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"COMPARAÇÃO DOS MODELOS\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7877dfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar tabela de comparação\n",
    "comparacao = pd.DataFrame({\n",
    "    'Modelo': ['Regressão Logística', 'Random Forest', 'SVM', 'XGBoost'],\n",
    "    'Acurácia': [\n",
    "        accuracy_score(y_test, y_pred_lr),\n",
    "        accuracy_score(y_test, y_pred_rf),\n",
    "        accuracy_score(y_test, y_pred_svm),\n",
    "        accuracy_score(y_test, y_pred_xgb)\n",
    "    ],\n",
    "    'Precisão': [\n",
    "        precision_score(y_test, y_pred_lr, average='weighted', zero_division=0),\n",
    "        precision_score(y_test, y_pred_rf, average='weighted', zero_division=0),\n",
    "        precision_score(y_test, y_pred_svm, average='weighted', zero_division=0),\n",
    "        precision_score(y_test, y_pred_xgb, average='weighted', zero_division=0)\n",
    "    ],\n",
    "    'Recall': [\n",
    "        recall_score(y_test, y_pred_lr, average='weighted', zero_division=0),\n",
    "        recall_score(y_test, y_pred_rf, average='weighted', zero_division=0),\n",
    "        recall_score(y_test, y_pred_svm, average='weighted', zero_division=0),\n",
    "        recall_score(y_test, y_pred_xgb, average='weighted', zero_division=0)\n",
    "    ],\n",
    "    'F1-Score': [\n",
    "        f1_score(y_test, y_pred_lr, average='weighted', zero_division=0),\n",
    "        f1_score(y_test, y_pred_rf, average='weighted', zero_division=0),\n",
    "        f1_score(y_test, y_pred_svm, average='weighted', zero_division=0),\n",
    "        f1_score(y_test, y_pred_xgb, average='weighted', zero_division=0)\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277e761d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + comparacao.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176b9458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar comparação\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "metricas = ['Acurácia', 'Precisão', 'Recall', 'F1-Score']\n",
    "for idx, metrica in enumerate(metricas):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    valores = comparacao[metrica].values\n",
    "    modelos = comparacao['Modelo'].values\n",
    "    bars = ax.bar(range(len(modelos)), valores, color=['#1f77b4', '#2ca02c', '#ff7f0e', '#d62728'], edgecolor='black', linewidth=1.5)\n",
    "    ax.set_ylabel(metrica, fontsize=11, fontweight='bold')\n",
    "    ax.set_title(f'{metrica} por Modelo', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.set_xticks(range(len(modelos)))\n",
    "    ax.set_xticklabels(modelos, rotation=45, ha='right')\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "    # Adicionar valores nas barras\n",
    "    for i, v in enumerate(valores):\n",
    "        ax.text(i, v + 0.02, f'{v:.3f}', ha='center', va='bottom', fontweight='bold', fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44c24b3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "plt.tight_layout()\n",
    "plt.savefig('comparacao_modelos.png', dpi=300, bbox_inches='tight')\n",
    "print(\"\\n✓ Gráfico salvo: comparacao_modelos.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ca1cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CÉLULA 20: ANÁLISE DETALHADA DOS RESULTADOS\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Análise crítica dos resultados obtidos, identificando o melhor modelo,\n",
    "discutindo limitações e propondo melhorias futuras.\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ANÁLISE DETALHADA DOS RESULTADOS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "melhor_modelo_idx = comparacao['F1-Score'].idxmax()\n",
    "melhor_modelo = comparacao.loc[melhor_modelo_idx, 'Modelo']\n",
    "melhor_f1 = comparacao.loc[melhor_modelo_idx, 'F1-Score']\n",
    "\n",
    "print(f\"\\nMELHOR MODELO: {melhor_modelo}\")\n",
    "print(f\"  F1-Score: {melhor_f1:.4f}\")\n",
    "print(f\"  Acurácia: {comparacao.loc[melhor_modelo_idx, 'Acurácia']:.4f}\")\n",
    "print(f\"  Precisão: {comparacao.loc[melhor_modelo_idx, 'Precisão']:.4f}\")\n",
    "print(f\"  Recall: {comparacao.loc[melhor_modelo_idx, 'Recall']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PONTOS FORTES E LIMITAÇÕES DOS MODELOS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n1. REGRESSÃO LOGÍSTICA:\")\n",
    "print(\"   Pontos Fortes:\")\n",
    "print(\"   - Modelo simples e interpretável\")\n",
    "print(\"   - Rápido para treinar\")\n",
    "print(\"   - Bom para dados linearmente separáveis\")\n",
    "print(\"   Limitações:\")\n",
    "print(\"   - Pode não capturar relações não-lineares complexas\")\n",
    "print(\"   - Sensível a outliers\")\n",
    "\n",
    "print(\"\\n2. RANDOM FOREST:\")\n",
    "print(\"   Pontos Fortes:\")\n",
    "print(\"   - Captura relações não-lineares\")\n",
    "print(\"   - Robusto a outliers\")\n",
    "print(\"   - Fornece importância das features\")\n",
    "print(\"   Limitações:\")\n",
    "print(\"   - Pode sofrer overfitting com dados pequenos\")\n",
    "print(\"   - Menos interpretável que regressão logística\")\n",
    "\n",
    "print(\"\\n3. SUPPORT VECTOR MACHINE (SVM):\")\n",
    "print(\"   Pontos Fortes:\")\n",
    "print(\"   - Excelente para classificação multiclasse\")\n",
    "print(\"   - Funciona bem com dados de alta dimensionalidade\")\n",
    "print(\"   - Kernels não-lineares capturam padrões complexos\")\n",
    "print(\"   Limitações:\")\n",
    "print(\"   - Computacionalmente caro para datasets grandes\")\n",
    "print(\"   - Menos interpretável\")\n",
    "print(\"   - Sensível ao scaling dos dados\")\n",
    "\n",
    "print(\"\\n4. XGBOOST:\")\n",
    "print(\"   Pontos Fortes:\")\n",
    "print(\"   - Melhor performance em muitos casos\")\n",
    "print(\"   - Regularização integrada reduz overfitting\")\n",
    "print(\"   - Fornece importância das features\")\n",
    "print(\"   Limitações:\")\n",
    "print(\"   - Mais complexo de tunar\")\n",
    "print(\"   - Requer mais dados para performance ótima\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa1f0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"\\n1. COLETA DE DADOS:\")\n",
    "print(\"   - Aumentar o volume de dados para melhor generalização\")\n",
    "print(\"   - Balancear melhor as classes de causa de óbito\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce710395",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n2. ENGENHARIA DE FEATURES:\")\n",
    "print(\"   - Criar features derivadas (ex: idade em grupos)\")\n",
    "print(\"   - Explorar interações entre variáveis\")\n",
    "print(\"   - Aplicar técnicas de redução de dimensionalidade (PCA)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c057b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n3. OTIMIZAÇÃO DE MODELOS:\")\n",
    "print(\"   - Explorar mais combinações de hiperparâmetros\")\n",
    "print(\"   - Usar ensemble de múltiplos modelos (Stacking, Voting)\")\n",
    "print(\"   - Implementar técnicas de regularização adicional\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4940da94",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n4. VALIDAÇÃO:\")\n",
    "print(\"   - Usar estratificação em todas as divisões\")\n",
    "print(\"   - Aplicar validação temporal se dados forem sequenciais\")\n",
    "print(\"   - Testar em dados completamente separados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ced9d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "Este projeto demonstrou a aplicação de 4 técnicas de Machine Learning para\n",
    "predição de causas de óbito no dataset DATASUS:\n",
    "\n",
    "1. Regressão Logística: Modelo baseline interpretável\n",
    "2. Random Forest: Ensemble robusto com boa performance\n",
    "3. Support Vector Machine: Técnica não vista em sala (ponto extra)\n",
    "4. XGBoost: Gradient boosting avançado\n",
    "\n",
    "METODOLOGIA APLICADA:\n",
    "✓ Pré-processamento: Limpeza, remoção de outliers, encoding\n",
    "✓ Seleção de atributos: SelectKBest com f_classif\n",
    "✓ Balanceamento: SMOTE para lidar com desbalanceamento\n",
    "✓ Normalização: StandardScaler para modelos sensíveis\n",
    "✓ Otimização: Grid Search com validação cruzada (5-fold)\n",
    "✓ Avaliação: Múltiplas métricas (Acurácia, Precisão, Recall, F1-Score)\n",
    "\n",
    "RESULTADO PRINCIPAL:\n",
    "O modelo {melhor_modelo} apresentou o melhor F1-Score ({melhor_f1:.4f}),\n",
    "indicando melhor balance entre precisão e recall para esta tarefa.\n",
    "\n",
    "APLICAÇÕES PRÁTICAS:\n",
    "- Análise epidemiológica automatizada\n",
    "- Suporte a decisões em saúde pública\n",
    "- Identificação de padrões em mortalidade\n",
    "- Alocação de recursos de prevenção\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ANÁLISE CONCLUÍDA COM SUCESSO!\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
